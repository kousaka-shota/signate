{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram\n",
    "n-gramとは任意の文字数で分割する手法のことである。\n",
    "\n",
    "「歯茎が歯垢だらけやん。歯をみがきなさないよ！！」\n",
    "\n",
    "のような文書があったとき\n",
    "\n",
    "|$n$|結果|\n",
    "|:----|:----|\n",
    "|1|歯/茎/が/歯/垢/だ/ら/け/や/ん/。/歯/を/み/が/き/な/さ/な/い/よ/！/！|\n",
    "|2|歯茎/茎が/が歯/歯垢/垢だ/だら/らけ/けや/やん/ん。/。歯/歯を/をみ/みが/がき/きな/なさ/さな/ない/いよ/よ！/！！|\n",
    "|3|歯茎が/茎が歯/が歯垢/歯垢だ/垢だら/だらけ/らけや/けやん/やん。/ん。歯/。歯を/歯をみ/をみが/みがき/がきな/きなさ/なさな/さない/ないよ/いよ！/よ！！|\n",
    "\n",
    "のような形で開始点をずらしながら$n$の文字数で分割する。実装例は以下の通り。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(text, n):\n",
    "    return [text[x:x+n] for x in range(len(text) -n +1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram('歯茎が歯垢だらけやん。歯をみがきなさないよ！！', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeCabのオプションのあれこれ\n",
    "MeCabを使用するには、python用のパッケージを用いる。オプションによってparseした時の結果が異なる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "坂本\t名詞,固有名詞,人名,姓,*,*,坂本,サカモト,サカモト\n",
      "勇人\t名詞,固有名詞,人名,名,*,*,勇人,ハヤト,ハヤト\n",
      "選手\t名詞,一般,*,*,*,*,選手,センシュ,センシュ\n",
      "チャンス\t名詞,一般,*,*,*,*,チャンス,チャンス,チャンス\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "打ち\t動詞,自立,*,*,五段・タ行,連用形,打つ,ウチ,ウチ\n",
      "損じる\t動詞,自立,*,*,一段,基本形,損じる,ソンジル,ソンジル\n",
      "EOS\n",
      "\n",
      "\n",
      "坂本\tサカモト\t坂本\t名詞-固有名詞-人名-姓\t\t\n",
      "勇人\tハヤト\t勇人\t名詞-固有名詞-人名-名\t\t\n",
      "選手\tセンシュ\t選手\t名詞-一般\t\t\n",
      "チャンス\tチャンス\tチャンス\t名詞-一般\t\t\n",
      "で\tデ\tで\t助詞-格助詞-一般\t\t\n",
      "打ち\tウチ\t打つ\t動詞-自立\t五段・タ行\t連用形\n",
      "損じる\tソンジル\t損じる\t動詞-自立\t一段\t基本形\n",
      "EOS\n",
      "\n",
      "\n",
      "坂本 勇人 選手 チャンス で 打ち 損じる \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "m = MeCab.Tagger('')\n",
    "print(m.parse('坂本勇人選手チャンスで打ち損じる'))\n",
    "print()\n",
    "m = MeCab.Tagger('-Ochasen')\n",
    "print(m.parse('坂本勇人選手チャンスで打ち損じる'))\n",
    "print()\n",
    "m = MeCab.Tagger('-Owakati')\n",
    "print(m.parse('坂本勇人選手チャンスで打ち損じる'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeCabの辞書を使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "坂本\t名詞,固有名詞,人名,姓,*,*,坂本,サカモト,サカモト\n",
      "勇人\t名詞,固有名詞,人名,名,*,*,勇人,ハヤト,ハヤト\n",
      "選手\t名詞,一般,*,*,*,*,選手,センシュ,センシュ\n",
      "チャンス\t名詞,一般,*,*,*,*,チャンス,チャンス,チャンス\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "打ち\t動詞,自立,*,*,五段・タ行,連用形,打つ,ウチ,ウチ\n",
      "損じる\t動詞,自立,*,*,一段,基本形,損じる,ソンジル,ソンジル\n",
      "EOS\n",
      "\n",
      "坂本勇人\t名詞,固有名詞,人名,一般,*,*,坂本勇人,サカモトハヤト,サカモトハヤト\n",
      "選手\t名詞,一般,*,*,*,*,選手,センシュ,センシュ\n",
      "チャンス\t名詞,一般,*,*,*,*,チャンス,チャンス,チャンス\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "打ち\t動詞,自立,*,*,五段・タ行,連用形,打つ,ウチ,ウチ\n",
      "損じる\t動詞,自立,*,*,一段,基本形,損じる,ソンジル,ソンジル\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "m = MeCab.Tagger('')\n",
    "print(m.parse('坂本勇人選手チャンスで打ち損じる'))\n",
    "m = MeCab.Tagger('-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "print(m.parse('坂本勇人選手チャンスで打ち損じる'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mojimoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ｶｯｺいいiphone11を買ったんだ\n",
      "カッコいいiphone11を買ったんだ\n",
      "カッコいいＩＰＨＯＮＥ１１を買ったんだ\n",
      "ｶｯｺいいＩＰＨＯＮＥ１１を買ったんだ\n"
     ]
    }
   ],
   "source": [
    "import mojimoji\n",
    "text = 'カッコいいｉＰｈｏｎｅ１１を買ったんだ'\n",
    "print(mojimoji.zen_to_han(text).lower())\n",
    "print(mojimoji.zen_to_han(text, kana=False).lower())\n",
    "text = 'ｶｯｺいいiphone11を買ったんだ'\n",
    "print(mojimoji.han_to_zen(text).upper())\n",
    "print(mojimoji.han_to_zen(text, kana=False).upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwordの削除\n",
    "slothlib:http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt  \n",
    "こちらを各自wgetで取得して、stopwords以下に保管しておいてください。  \n",
    "$ wget http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_words(text, stop_word_pass='../stopwords/Japanese.txt'):\n",
    "    # stopword listをつくる\n",
    "    stopword_list = []\n",
    "    with open(stop_word_pass, 'r') as f:\n",
    "        stopword_list = f.readlines()\n",
    "        \n",
    "    stopword_list = [x.strip() for x in stopword_list if x.strip()] \n",
    "    #形態素解析を始める\n",
    "    m = MeCab.Tagger('-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "    m.parse('')\n",
    "    #text = normalize_text(text)\n",
    "    text = mojimoji.zen_to_han(text, kana=False)\n",
    "    m_text = m.parse(text)\n",
    "    basic_words = []\n",
    "    #mecabの出力結果を単語ごとにリスト化\n",
    "    m_text = m_text.split('\\n')\n",
    "    for row in m_text:\n",
    "        #Tab区切りで形態素、その品詞等の内容と分かれているので単語部のみ取得\n",
    "        word = row.split(\"\\t\")[0]\n",
    "        #最終行はEOS\n",
    "        if word == 'EOS':\n",
    "            break\n",
    "        else:\n",
    "            pos = row.split('\\t')[1]\n",
    "            slice_ = pos.split(',')\n",
    "            #品詞を取得する\n",
    "            parts = slice_[0]\n",
    "            if parts == '記号':\n",
    "                continue\n",
    "\n",
    "            #活用語の場合は活用指定ない原型を取得する。\n",
    "            elif slice_[0] in ('形容詞', '動詞') and slice_[-3] not in stopword_list:\n",
    "                    basic_words.append(slice_[-3])\n",
    "\n",
    "            #活用しない語についてはそのままの語を取得する\n",
    "            elif slice_[0] =='名詞' and word not in stopword_list:\n",
    "                basic_words.append(word)\n",
    "\n",
    "    basic_words = ' '.join(basic_words)\n",
    "    return basic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'坂本勇人 選手 チャンス 打つ 損じる'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_words('坂本勇人選手チャンスで打ち損じる')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
